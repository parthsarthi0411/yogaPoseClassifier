{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewYogaNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmCDv0qV_Fo6",
        "colab_type": "text"
      },
      "source": [
        "This project detects keypoints on an image of a yoga posture and tries to classify it. OpenPose is used to detect the keypoints and we use XGBoost to classify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwi41t8i-WUp",
        "colab_type": "text"
      },
      "source": [
        "Installing OpenPose. We download and build the OpenPose repo from git to this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdVZ8wFmt_e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to download openpose and build \n",
        "#install OpenPose\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CMU-Perceptual-Computing-Lab/openpose.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # install new CMake\n",
        "  !wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz\n",
        "  !tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local\n",
        "  # clone openpose git\n",
        "  !git clone -q --depth 1 $git_repo_url\n",
        "  !sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
        "  # install system dependencies and libraries\n",
        "  !apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev\n",
        "  # build openpose\n",
        "  !cd openpose && rm -rf build || true && mkdir build && cd build && cmake -DBUILD_PYTHON=ON .. && make -j`nproc`\n",
        "  \n",
        "\n",
        "print(\"installation done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G80XrH2hKsFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73e61b9d-1574-4082-cad4-b4154c417bb5"
      },
      "source": [
        "!cd /content/openpose/build/python/ && pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/openpose/build/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwmZO48q_9RF",
        "colab_type": "text"
      },
      "source": [
        "Building the Python wrapper for OpenPose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNTTwc3zugfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4789eb0c-b67c-4f09-e8ca-3bf131215d7f"
      },
      "source": [
        "os.chdir('/content/openpose/build/python/')\n",
        "os.getcwd( )\n",
        "\n",
        "!sudo make install -j `nproc`"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 97%] Built target openpose\n",
            "[100%] Built target pyopenpose\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"Release\"\n",
            "-- Up-to-date: /usr/local/python/pyopenpose.cpython-36m-x86_64-linux-gnu.so\n",
            "-- Up-to-date: /usr/local/python/openpose\n",
            "-- Up-to-date: /usr/local/python/openpose/CMakeFiles\n",
            "-- Up-to-date: /usr/local/python/openpose/CMakeFiles/pyopenpose.dir\n",
            "-- Up-to-date: /usr/local/python/openpose/pyopenpose.cpython-36m-x86_64-linux-gnu.so\n",
            "-- Up-to-date: /usr/local/python/openpose\n",
            "-- Up-to-date: /usr/local/python/openpose/__init__.py\n",
            "-- Up-to-date: /usr/local/python/openpose/CMakeFiles\n",
            "-- Up-to-date: /usr/local/python/openpose/CMakeFiles/pyopenpose.dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU9AcOuoAU9C",
        "colab_type": "text"
      },
      "source": [
        "Mounting the Google Drive where the dataset is placed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaIwomvU36fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "727b1a3c-cb1b-4e3d-a4d1-49f4f205e2b7"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/mnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb2AzKsh41jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import cv2\n",
        "\n",
        "from sys import platform\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "from openpose import pyopenpose as op\n",
        "\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU3D-G_vZb-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acaa0bde-1bb7-4145-b345-0cbff935d9af"
      },
      "source": [
        "print(myData.poseKeypoints)\n",
        "\n",
        "\n",
        "new_dF = myData.poseKeypoints.reshape (-1,3)\n",
        "new_dF = pd.DataFrame (new_dF, columns = ['X', 'Y', 'P'])\n",
        "\n",
        "new_dF = new_dF.iloc[0:25]\n",
        "\n",
        "\n",
        "print(type(myData.poseKeypoints))\n",
        "print(myData.poseKeypoints.shape)\n",
        "print(new_dF)\n",
        "\n",
        "new_dF = new_dF.T\n",
        "\n",
        "new_dF = new_dF.join(new_dF.shift(-1).add_prefix('y_'))\n",
        "new_dF[1::2] = ''\n",
        "\n",
        "new_dF=new_dF.drop(['Y','P'])\n",
        "print(new_dF) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [1.8841925e+02 3.4100290e+02 3.0423397e-01]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [1.4583594e+02 3.4413120e+02 4.5311826e-01]\n",
            "  [1.5412740e+02 3.4724411e+02 4.2625058e-01]\n",
            "  [1.8944478e+02 3.4931631e+02 2.5667292e-01]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
            "\n",
            " [[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [4.5520914e+02 7.0044853e+01 9.1951422e-02]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [4.5416953e+02 6.6949654e+01 1.0061037e-01]\n",
            "  [5.2893170e+02 1.7181091e+02 2.6453698e-01]\n",
            "  [6.1818945e+02 3.0778384e+02 3.6375612e-01]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [5.5283173e+02 3.1507300e+02 2.4212867e-01]\n",
            "  [5.5696014e+02 3.2026834e+02 2.1165414e-01]\n",
            "  [6.2861066e+02 3.1504953e+02 3.1429774e-01]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            "  [0.0000000e+00 0.0000000e+00 0.0000000e+00]]]\n",
            "<class 'numpy.ndarray'>\n",
            "(2, 25, 3)\n",
            "             X           Y         P\n",
            "0     0.000000    0.000000  0.000000\n",
            "1     0.000000    0.000000  0.000000\n",
            "2     0.000000    0.000000  0.000000\n",
            "3     0.000000    0.000000  0.000000\n",
            "4     0.000000    0.000000  0.000000\n",
            "5     0.000000    0.000000  0.000000\n",
            "6     0.000000    0.000000  0.000000\n",
            "7     0.000000    0.000000  0.000000\n",
            "8     0.000000    0.000000  0.000000\n",
            "9     0.000000    0.000000  0.000000\n",
            "10    0.000000    0.000000  0.000000\n",
            "11    0.000000    0.000000  0.000000\n",
            "12    0.000000    0.000000  0.000000\n",
            "13    0.000000    0.000000  0.000000\n",
            "14  188.419250  341.002899  0.304234\n",
            "15    0.000000    0.000000  0.000000\n",
            "16    0.000000    0.000000  0.000000\n",
            "17    0.000000    0.000000  0.000000\n",
            "18    0.000000    0.000000  0.000000\n",
            "19  145.835938  344.131195  0.453118\n",
            "20  154.127396  347.244110  0.426251\n",
            "21  189.444778  349.316315  0.256673\n",
            "22    0.000000    0.000000  0.000000\n",
            "23    0.000000    0.000000  0.000000\n",
            "24    0.000000    0.000000  0.000000\n",
            "   0  1  2  3  4  5  6  7  ... y_17 y_18     y_19     y_20     y_21 y_22 y_23 y_24\n",
            "X  0  0  0  0  0  0  0  0  ...    0    0  344.131  347.244  349.316    0    0    0\n",
            "\n",
            "[1 rows x 50 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A510Nh6qBCcn",
        "colab_type": "text"
      },
      "source": [
        "Pointing to the directory where the image files are stored. A JSON file with the keypoints is created for each of the images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpl2DE0aLNoC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b152ac55-6544-401e-c10a-9a62b7ceec55"
      },
      "source": [
        "#/content/mnt/My Drive/Datasets/YogaPoses/bhujangasana\n",
        "\n",
        "!cd openpose && ./build/examples/openpose/openpose.bin --image_dir ../mnt/My\\ Drive/Datasets/YogaPoses/uttanasana --write_json ../Uthanasana/ --display 0 --render_pose 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 9.079009 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJXOP0F1DBKz",
        "colab_type": "text"
      },
      "source": [
        "A samples JSON looks like: \n",
        "\n",
        "> {\"version\":1.3,\"people\":[{\"person_id\":[-1],\"pose_keypoints_2d\":[248.431,219.657,0.285197,263.262,175.994,0.196737,233.555,181.559,0.14297,0,0,0,0,0,0,287.387,175.994,0.093796,227.975,256.764,0.801577,159.283,305.035,0.780612,340.313,123.994,0.0544115,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,241.001,218.665,0.56429,0,0,0,240.042,202.92,0.787322,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"face_keypoints_2d\":[],\"hand_left_keypoints_2d\":[],\"hand_right_keypoints_2d\":[],\"pose_keypoints_3d\":[],\"face_keypoints_3d\":[],\"hand_left_keypoints_3d\":[],\"hand_right_keypoints_3d\":[]},{\"person_id\":[-1],\"pose_keypoints_2d\":[0,0,0,0,0,0,275.32,197.334,0.0854624,190.85,227.97,0.559881,131.418,278.089,0.790055,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"face_keypoints_2d\":[],\"hand_left_keypoints_2d\":[],\"hand_right_keypoints_2d\":[],\"pose_keypoints_3d\":[],\"face_keypoints_3d\":[],\"hand_left_keypoints_3d\":[],\"hand_right_keypoints_3d\":[]},{\"person_id\":[-1],\"pose_keypoints_2d\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,399.74,40.4328,0.328281,383.026,45.0668,0.14178,0,0,0,0,0,0,414.609,39.5025,0.407715,477.716,149.983,0.49397,527.864,258.6,0.629395,0,0,0,0,0,0,0,0,0,0,0,0,499.091,278.09,0.37415,508.363,278.139,0.379254,537.125,265.12,0.554026,0,0,0,0,0,0,0,0,0],\"face_keypoints_2d\":[],\"hand_left_keypoints_2d\":[],\"hand_right_keypoints_2d\":[],\"pose_keypoints_3d\":[],\"face_keypoints_3d\":[],\"hand_left_keypoints_3d\":[],\"hand_right_keypoints_3d\":[]}]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7VN12NSRole",
        "colab_type": "text"
      },
      "source": [
        "[https://marc.schulder.info/files/slides/2019_10_03_openpose_for_linguists.pdf\n",
        "\n",
        "A detailed description of what the JSON means can be found in the above mentioned link. For our use-case, we need just the numbers in the *pose_keypoints_2d*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWKYF6e60paY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CODE FOR CLASSIFICATION\n",
        "\n",
        "import os, json\n",
        "import pickle\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGTBZTibS4ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Labels\n",
        "pose_list = [\"AdhoMukhaSwana\",\"Bhujangasana\",\"Uthanasana\",\"chathuranga\"]\n",
        "# A dataframe to store all the JSONs.\n",
        "Main_DataFrame = pd.DataFrame()\n",
        "path_to_json_parent = '/content/mnt/My Drive/Datasets/YogaPoses/YogaposesJSON/content/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3BvVrVy03Ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to preprocess the JSON.\n",
        "\n",
        "def preprocess_json(pose_name):\n",
        "\n",
        "      path_to_json = path_to_json_parent+pose_name\n",
        "      json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
        "      global Main_DataFrame\n",
        "\n",
        "\n",
        "\n",
        "      # we need both the json and an index number so use enumerate()\n",
        "      for index, js in enumerate(json_files):\n",
        "        with open(os.path.join(path_to_json, js)) as json_file:\n",
        "            json_text = json.load(json_file)\n",
        "          \n",
        "            #Extracting hte pose_keypoints_2d from the JSON and adding it to a Dataframe.\n",
        "\n",
        "            try:\n",
        "              json_text = np.array(json_text ['people'] [0] ['pose_keypoints_2d']). reshape (-1,3)\n",
        "              #print(json_text1)\n",
        "              df = pd.DataFrame (json_text, columns = ['X', 'Y', 'P'])\n",
        "              df = df.T\n",
        "\n",
        "              df = df.join(df.shift(-1).add_prefix('y_'))\n",
        "              df[1::2] = ''\n",
        "\n",
        "              df=df.drop(['Y','P'])\n",
        "              print(df) \n",
        "              df['Label'] = pose_name\n",
        "\n",
        "\n",
        "              Main_DataFrame = Main_DataFrame.append(df,ignore_index=True)\n",
        "              #print(\"mainDataFrame\") \n",
        "              #print(mainDataFrame) \n",
        "            except IndexError:\n",
        "              json_text = 'null'\n",
        "\n",
        "                \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaQt00W2SvWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run hte function for each of the label\n",
        "for pose_name in pose_list:\n",
        "  preprocess_json(pose_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y0mGZZYTQzO",
        "colab_type": "text"
      },
      "source": [
        "Now we have to split our data into Training and Test data. Firstly, we would map our input as x and y co ordinates of 24 keypoints) and output as the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKzRN3gPP9-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Spliting the points and the labels\n",
        "X = Main_DataFrame.iloc[:, :-1].values  \n",
        "y = Main_DataFrame.iloc[:, 50].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6FtpgmLP_rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# And split the data into appropriate data sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxGDjUUrQgdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = list(set(y))\n",
        "num_class = len(class_names)\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-uNRGtuQlH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the XGBoost classifier. # Gradient Boosting\n",
        "clf = XGBClassifier(max_depth=6, \n",
        "                    learning_rate=0.01, \n",
        "                    n_estimators=500, \n",
        "                    objective='multi:softmax', \n",
        "                    n_jobs=cores, \n",
        "                    num_class=num_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o--kpOemQmY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training the model\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxXcBh56QuSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "6b696082-6788-42bf-a2a2-f6e1196ba4c6"
      },
      "source": [
        "# Generating the confusion matrix and the model summary.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "print(conf_matrix)\n",
        "\n",
        "class_report = classification_report(y_test, preds)\n",
        "print(class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11  0  1  0]\n",
            " [ 0  8  1  0]\n",
            " [ 0  0  6  3]\n",
            " [ 0  2  2 16]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "AdhoMukhaSwana       1.00      0.92      0.96        12\n",
            "  Bhujangasana       0.80      0.89      0.84         9\n",
            "    Uthanasana       0.60      0.67      0.63         9\n",
            "   chathuranga       0.84      0.80      0.82        20\n",
            "\n",
            "      accuracy                           0.82        50\n",
            "     macro avg       0.81      0.82      0.81        50\n",
            "  weighted avg       0.83      0.82      0.82        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhH1XEDeRBNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the model\n",
        "filename = '/content/models/yoga_poses.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L4-1VaSSb_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "09493dab-714b-4e97-d513-219e74b8d781"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bhujangasana', 'Bhujangasana', 'chathuranga', 'chathuranga',\n",
              "       'chathuranga', 'chathuranga', 'chathuranga', 'Bhujangasana',\n",
              "       'chathuranga', 'Bhujangasana', 'AdhoMukhaSwana', 'AdhoMukhaSwana',\n",
              "       'Uthanasana', 'chathuranga', 'Uthanasana', 'Uthanasana',\n",
              "       'chathuranga', 'AdhoMukhaSwana', 'chathuranga', 'chathuranga',\n",
              "       'chathuranga', 'Bhujangasana', 'Bhujangasana', 'chathuranga',\n",
              "       'Uthanasana', 'chathuranga', 'chathuranga', 'Bhujangasana',\n",
              "       'chathuranga', 'AdhoMukhaSwana', 'AdhoMukhaSwana',\n",
              "       'AdhoMukhaSwana', 'Uthanasana', 'AdhoMukhaSwana', 'chathuranga',\n",
              "       'chathuranga', 'AdhoMukhaSwana', 'Uthanasana', 'Bhujangasana',\n",
              "       'Bhujangasana', 'Bhujangasana', 'chathuranga', 'AdhoMukhaSwana',\n",
              "       'Uthanasana', 'chathuranga', 'Bhujangasana', 'Bhujangasana',\n",
              "       'Bhujangasana', 'Uthanasana', 'Uthanasana'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkhEQ2-FbVFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Doing Inference on a sample image from the internet\n",
        "\n",
        "sample_image =  \"https://www.miencuentroconmigo.com.ar/wp-content/uploads/2018/03/perro-hacia-abajo.jpg\"\n",
        "\n",
        "import requests\n",
        "\n",
        "img_data = requests.get(sample_image).content\n",
        "with open('image_name.jpg', 'wb') as handler:\n",
        "    handler.write(img_data)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVxIBAUb3AQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b5312658-cdea-4e61-a73c-fa586b0c2a90"
      },
      "source": [
        "!cd openpose && ./build/examples/openpose/openpose.bin --image_dir ../openpose/build/python/ --write_json ../Uthanasana/ --display 0 --render_pose 0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 6.338830 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QgjaIF1eH35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a5f56aab-a975-478f-a6a7-13dd324771aa"
      },
      "source": [
        "      path_to_json = '/content/Uthanasana/'\n",
        "      json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
        "      test_DataFrame = pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "      # we need both the json and an index number so use enumerate()\n",
        "      for index, js in enumerate(json_files):\n",
        "        with open(os.path.join(path_to_json, js)) as json_file:\n",
        "            json_text2 = json.load(json_file)\n",
        "            print(json_text2)\n",
        "            # here you need to know the layout of your json and each json has to have\n",
        "            # the same structure (obviously not the structure I have here)\n",
        "\n",
        "            try:\n",
        "              json_text1 = np.array(json_text2 ['people'] [0] ['pose_keypoints_2d']). reshape (-1,3)\n",
        "              #print(json_text1)\n",
        "              df = pd.DataFrame (json_text1, columns = ['X', 'Y', 'P'])\n",
        "              df = df.T\n",
        "\n",
        "              df = df.join(df.shift(-1).add_prefix('y_'))\n",
        "              df[1::2] = ''\n",
        "\n",
        "              df=df.drop(['Y','P'])\n",
        "              print(df) \n",
        "              df['Label'] = \"DownwardDogs\"\n",
        "\n",
        "\n",
        "              test_DataFrame = test_DataFrame.append(df,ignore_index=True)\n",
        "              #print(\"mainDataFrame\") \n",
        "              #print(mainDataFrame) \n",
        "            except IndexError:\n",
        "              json_text1 = 'null'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'version': 1.3, 'people': [{'person_id': [-1], 'pose_keypoints_2d': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 895.942, 218.498, 0.11408, 1102.39, 468.557, 0.253852, 1271.01, 747.689, 0.660162, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1166.34, 779.578, 0.463474, 1189.58, 785.527, 0.399337, 1297.18, 765.154, 0.735113, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'face_keypoints_2d': [], 'hand_left_keypoints_2d': [], 'hand_right_keypoints_2d': [], 'pose_keypoints_3d': [], 'face_keypoints_3d': [], 'hand_left_keypoints_3d': [], 'hand_right_keypoints_3d': []}, {'person_id': [-1], 'pose_keypoints_2d': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 913.352, 221.504, 0.143163, 933.758, 218.539, 0.107179, 1090.77, 454.04, 0.118886, 1247.69, 736.057, 0.259366, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1151.69, 776.671, 0.435561, 1151.72, 770.843, 0.359482, 0, 0, 0], 'face_keypoints_2d': [], 'hand_left_keypoints_2d': [], 'hand_right_keypoints_2d': [], 'pose_keypoints_3d': [], 'face_keypoints_3d': [], 'hand_left_keypoints_3d': [], 'hand_right_keypoints_3d': []}]}\n",
            "   0  1  2  3  4  5  6  7  ... y_17 y_18     y_19     y_20     y_21 y_22 y_23 y_24\n",
            "X  0  0  0  0  0  0  0  0  ...    0    0  779.578  785.527  765.154    0    0    0\n",
            "\n",
            "[1 rows x 50 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQMV3Q2bfBdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83fb4e57-8aca-499e-e60b-6fb591884611"
      },
      "source": [
        "test_DataFrame\n",
        "test_DataFrame = test_DataFrame.drop(['Label'],axis=1)\n",
        "test_DataFrame\n",
        "\n",
        "\n",
        "new_preds = clf.predict(test_DataFrame.values)\n",
        "new_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AdhoMukhaSwana'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fNH5PofUset",
        "colab_type": "text"
      },
      "source": [
        "And it predicted correctly :)"
      ]
    }
  ]
}